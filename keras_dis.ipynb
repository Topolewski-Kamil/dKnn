{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_dis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOx7ytOqLIjB9+7dlyYvqs2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Topolewski-Kamil/dKnn/blob/main/keras_dis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "R8g5IEVO-lZC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "SnZbGpex18E5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras import backend as K\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model / data parameters\n",
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "# Make sure images have shape (28, 28, 1)\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXAsY2jo1_y7",
        "outputId": "eade42ea-9602-47e0-cef0-7be820a7af6b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(64, kernel_size=(8, 8), strides=(2,2), padding=\"same\", activation=\"relu\", input_shape=x_train.shape[1:]),\n",
        "        layers.Conv2D(128, kernel_size=(6, 6), strides=(2,2), padding=\"valid\", activation=\"relu\"),\n",
        "        layers.Conv2D(128, kernel_size=(5, 5), strides=(1,1), padding=\"valid\", activation=\"relu\"),\n",
        "        layers.Flatten(),\n",
        "        # layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_iCpdEz2HSB",
        "outputId": "24699588-08a4-474f-c8e1-999817281498"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 14, 14, 64)        4160      \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 5, 5, 128)         295040    \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 1, 1, 128)         409728    \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 710,218\n",
            "Trainable params: 710,218\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 500\n",
        "epochs = 8\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3B38_uDY5Wum",
        "outputId": "c8578d0b-4699-4011-cdbe-fc4e744a0c3f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "108/108 [==============================] - 6s 50ms/step - loss: 0.3679 - accuracy: 0.8897 - val_loss: 0.1026 - val_accuracy: 0.9702\n",
            "Epoch 2/8\n",
            "108/108 [==============================] - 5s 47ms/step - loss: 0.0830 - accuracy: 0.9746 - val_loss: 0.0574 - val_accuracy: 0.9815\n",
            "Epoch 3/8\n",
            "108/108 [==============================] - 5s 47ms/step - loss: 0.0544 - accuracy: 0.9831 - val_loss: 0.0518 - val_accuracy: 0.9840\n",
            "Epoch 4/8\n",
            "108/108 [==============================] - 5s 47ms/step - loss: 0.0399 - accuracy: 0.9880 - val_loss: 0.0473 - val_accuracy: 0.9855\n",
            "Epoch 5/8\n",
            "108/108 [==============================] - 5s 47ms/step - loss: 0.0307 - accuracy: 0.9901 - val_loss: 0.0546 - val_accuracy: 0.9858\n",
            "Epoch 6/8\n",
            "108/108 [==============================] - 5s 48ms/step - loss: 0.0251 - accuracy: 0.9924 - val_loss: 0.0415 - val_accuracy: 0.9892\n",
            "Epoch 7/8\n",
            "108/108 [==============================] - 5s 47ms/step - loss: 0.0194 - accuracy: 0.9941 - val_loss: 0.0398 - val_accuracy: 0.9898\n",
            "Epoch 8/8\n",
            "108/108 [==============================] - 5s 46ms/step - loss: 0.0141 - accuracy: 0.9957 - val_loss: 0.0437 - val_accuracy: 0.9892\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9f1ec29650>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0k9rrKu2_6dT",
        "outputId": "5e7fac53-3303-444f-b718-02c56f505c2b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.035352423787117004\n",
            "Test accuracy: 0.9889000058174133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers:\n",
        "  print(layer.output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejTJ9loRDY8R",
        "outputId": "e8b72884-a5df-4e2e-a295-46a5f2bb4902"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 64), dtype=tf.float32, name=None), name='conv2d/Relu:0', description=\"created by layer 'conv2d'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 5, 5, 128), dtype=tf.float32, name=None), name='conv2d_1/Relu:0', description=\"created by layer 'conv2d_1'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 128), dtype=tf.float32, name=None), name='conv2d_2/Relu:0', description=\"created by layer 'conv2d_2'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name=None), name='flatten/Reshape:0', description=\"created by layer 'flatten'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name=None), name='dense/BiasAdd:0', description=\"created by layer 'dense'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name=None), name='dense_1/Softmax:0', description=\"created by layer 'dense_1'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr = [1,2,3,4,5]\n",
        "arr[0:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3ly-_1vE_2S",
        "outputId": "27e6b86c-6724-4cd7-c4f1-115f46b600c6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot one of the mnist images\n",
        "plt.imshow( x_train[1].reshape((28, 28), order='F'))\n",
        "cbar = plt.colorbar()\n",
        "cbar.set_label('Pixel Intensity')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "jIKn0Yd9L0bL",
        "outputId": "55f0c85f-c124-401b-b0be-0db000055673"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsZGoHdomf3N",
        "outputId": "a04ec264-876d-4cae-bd71-261a152a23d5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layerIndex = 1\n",
        "func = K.function([model.get_layer(index=0).input], model.get_layer(index=layerIndex).output)\n",
        "layerOutput = func(x_train)  # input_data is a numpy array\n",
        "print(layerOutput)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSVR3lUCXIly",
        "outputId": "13f37953-29be-44a1-d1f8-2dd4e2be31cc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[3.19602415e-02 5.82224667e-01 9.53250527e-01 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 6.33800745e-01 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 1.19393146e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]]\n",
            "\n",
            "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 9.03749168e-01\n",
            "    1.23895504e-01 0.00000000e+00]\n",
            "   [1.03792357e+00 0.00000000e+00 1.64660192e+00 ... 9.00753796e-01\n",
            "    0.00000000e+00 9.59440649e-01]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 2.53154248e-01\n",
            "    0.00000000e+00 5.48127294e-01]\n",
            "   [2.28441164e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 1.26010358e+00]\n",
            "   [3.40593368e-01 0.00000000e+00 1.41670197e-01 ... 0.00000000e+00\n",
            "    0.00000000e+00 1.22053897e+00]]\n",
            "\n",
            "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [1.80736735e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [1.67389071e+00 0.00000000e+00 7.27676749e-01 ... 0.00000000e+00\n",
            "    0.00000000e+00 4.53837067e-01]\n",
            "   [0.00000000e+00 5.17359316e-01 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 5.04144192e-01 0.00000000e+00 ... 0.00000000e+00\n",
            "    3.72313350e-01 4.72051919e-01]]\n",
            "\n",
            "  [[0.00000000e+00 6.75354064e-01 0.00000000e+00 ... 5.27137816e-01\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [3.71149153e-01 1.90354884e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [7.62173355e-01 4.92658198e-01 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 7.48501062e-01 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 1.53833240e-01 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]]\n",
            "\n",
            "  [[0.00000000e+00 2.74916679e-01 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    6.51961207e-01 0.00000000e+00]\n",
            "   [6.06028140e-01 0.00000000e+00 2.47464672e-01 ... 8.56316209e-01\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [3.19314450e-01 0.00000000e+00 1.09804606e+00 ... 5.86647868e-01\n",
            "    0.00000000e+00 8.65838826e-01]\n",
            "   [1.00800395e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 4.45437044e-01]]]\n",
            "\n",
            "\n",
            " [[[0.00000000e+00 2.18611941e-01 0.00000000e+00 ... 1.02875076e-01\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [2.69726396e-01 2.68162400e-01 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 1.86533117e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    5.92501283e-01 0.00000000e+00]\n",
            "   [0.00000000e+00 6.56551957e-01 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 1.55134827e-01 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]]\n",
            "\n",
            "  [[2.27223873e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 1.07112730e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    2.41759491e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 4.63371694e-01\n",
            "    1.30750582e-01 0.00000000e+00]\n",
            "   [1.76888692e+00 0.00000000e+00 1.21654582e+00 ... 2.02443600e-01\n",
            "    0.00000000e+00 1.01091671e+00]\n",
            "   [0.00000000e+00 4.01583046e-01 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]]\n",
            "\n",
            "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    1.42503226e+00 2.44949490e-01]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    1.28389943e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [8.68313015e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 8.40327680e-01 0.00000000e+00 ... 0.00000000e+00\n",
            "    2.75359511e-01 0.00000000e+00]]\n",
            "\n",
            "  [[3.42277549e-02 0.00000000e+00 9.90688264e-01 ... 0.00000000e+00\n",
            "    1.04091239e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 1.36084545e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 1.57888818e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 4.62503880e-01 0.00000000e+00 ... 0.00000000e+00\n",
            "    2.50249004e+00 2.19396740e-01]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]]\n",
            "\n",
            "  [[8.91782463e-01 0.00000000e+00 2.17134342e-01 ... 0.00000000e+00\n",
            "    0.00000000e+00 5.88173158e-02]\n",
            "   [0.00000000e+00 0.00000000e+00 3.20612490e-01 ... 6.18109465e-01\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 1.37812150e+00 ... 1.22816622e+00\n",
            "    2.18724862e-01 0.00000000e+00]\n",
            "   [1.73942536e-01 0.00000000e+00 1.38887477e+00 ... 4.62082803e-01\n",
            "    0.00000000e+00 7.60697067e-01]\n",
            "   [0.00000000e+00 0.00000000e+00 1.29158497e-02 ... 0.00000000e+00\n",
            "    0.00000000e+00 2.30240226e-01]]]\n",
            "\n",
            "\n",
            " [[[0.00000000e+00 6.70570135e-01 0.00000000e+00 ... 0.00000000e+00\n",
            "    8.55334103e-01 0.00000000e+00]\n",
            "   [0.00000000e+00 2.70287722e-01 0.00000000e+00 ... 0.00000000e+00\n",
            "    1.61530405e-01 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [3.52740645e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 1.32648543e-01]\n",
            "   [0.00000000e+00 9.10703897e-01 0.00000000e+00 ... 0.00000000e+00\n",
            "    1.30292284e+00 0.00000000e+00]]\n",
            "\n",
            "  [[0.00000000e+00 4.90545809e-01 0.00000000e+00 ... 0.00000000e+00\n",
            "    9.20437276e-01 0.00000000e+00]\n",
            "   [0.00000000e+00 5.92931271e-01 0.00000000e+00 ... 1.65431067e-01\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [3.76488678e-02 6.46593928e-01 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [5.91101609e-02 6.65868700e-01 0.00000000e+00 ... 0.00000000e+00\n",
            "    1.45017385e+00 3.01690698e-01]\n",
            "   [0.00000000e+00 3.90254587e-01 0.00000000e+00 ... 0.00000000e+00\n",
            "    5.60312808e-01 0.00000000e+00]]\n",
            "\n",
            "  [[0.00000000e+00 4.33048546e-01 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 4.68504071e-01 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    1.47472930e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 6.74091280e-02 0.00000000e+00 ... 1.46660760e-01\n",
            "    0.00000000e+00 0.00000000e+00]]\n",
            "\n",
            "  [[6.06682777e-01 0.00000000e+00 0.00000000e+00 ... 9.98547018e-01\n",
            "    0.00000000e+00 5.69890320e-01]\n",
            "   [4.75474924e-01 0.00000000e+00 2.08077841e-02 ... 6.78519845e-01\n",
            "    0.00000000e+00 9.60804462e-01]\n",
            "   [8.47395718e-01 0.00000000e+00 1.56951815e-01 ... 0.00000000e+00\n",
            "    0.00000000e+00 1.40359628e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 5.73944032e-01 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 1.45318851e-01]]\n",
            "\n",
            "  [[3.53980482e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 4.25453871e-01]\n",
            "   [1.80423558e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 4.86091733e-01]\n",
            "   [4.60644454e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 1.05699348e+00]\n",
            "   [1.05505753e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 2.51185834e-01 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[0.00000000e+00 3.65923226e-01 8.26479718e-02 ... 1.18619613e-01\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 6.47572041e-01 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 1.82344234e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 1.07412972e-03 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]]\n",
            "\n",
            "  [[1.85387909e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 2.41479427e-01 1.06216586e+00 ... 0.00000000e+00\n",
            "    6.56593442e-01 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 3.93008813e-02\n",
            "    1.09028351e+00 0.00000000e+00]\n",
            "   [5.30289650e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 1.36710846e+00]\n",
            "   [3.31360877e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 1.25083113e+00]]\n",
            "\n",
            "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 2.83912152e-01\n",
            "    1.64020360e-01 1.93724781e-01]\n",
            "   [8.67747962e-01 0.00000000e+00 1.99893445e-01 ... 1.09309822e-01\n",
            "    0.00000000e+00 9.47315395e-02]\n",
            "   [9.57135618e-01 0.00000000e+00 5.96175969e-01 ... 0.00000000e+00\n",
            "    0.00000000e+00 3.88778627e-01]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    5.27338590e-03 0.00000000e+00]\n",
            "   [0.00000000e+00 3.35965119e-02 0.00000000e+00 ... 0.00000000e+00\n",
            "    1.70547023e-01 5.40455043e-01]]\n",
            "\n",
            "  [[0.00000000e+00 1.40399083e-01 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 2.29410842e-01\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [1.90042961e+00 0.00000000e+00 1.20377429e-02 ... 0.00000000e+00\n",
            "    0.00000000e+00 8.45837235e-01]\n",
            "   [0.00000000e+00 1.16238403e+00 0.00000000e+00 ... 6.93243816e-02\n",
            "    0.00000000e+00 9.39386114e-02]\n",
            "   [0.00000000e+00 4.17564958e-01 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]]\n",
            "\n",
            "  [[0.00000000e+00 7.38476515e-01 4.85933840e-01 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 6.40898645e-01 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    1.05608070e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 2.41048887e-01 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]]]\n",
            "\n",
            "\n",
            " [[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [3.46178025e-01 3.04669291e-01 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 1.03191924e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    1.02100277e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    1.56580567e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 8.72278959e-02 ... 0.00000000e+00\n",
            "    0.00000000e+00 1.74840912e-01]]\n",
            "\n",
            "  [[2.90795118e-01 4.73227873e-02 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 6.23237491e-01 0.00000000e+00 ... 0.00000000e+00\n",
            "    1.03040993e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 4.41675335e-02\n",
            "    2.00306869e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 3.93048264e-02]\n",
            "   [1.52580142e-01 4.49152201e-01 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 2.15520114e-01]]\n",
            "\n",
            "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 1.36988997e-01]\n",
            "   [0.00000000e+00 3.31204087e-01 0.00000000e+00 ... 0.00000000e+00\n",
            "    1.83746076e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [2.06431925e-01 2.79825300e-01 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 4.53940630e-01 0.00000000e+00 ... 0.00000000e+00\n",
            "    1.52374268e-01 0.00000000e+00]]\n",
            "\n",
            "  [[0.00000000e+00 3.02447081e-01 9.17374253e-01 ... 0.00000000e+00\n",
            "    8.94560754e-01 0.00000000e+00]\n",
            "   [0.00000000e+00 5.91985941e-01 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 1.96146108e-02 0.00000000e+00 ... 0.00000000e+00\n",
            "    4.40841377e-01 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 2.94254571e-01]\n",
            "   [1.64614350e-01 0.00000000e+00 0.00000000e+00 ... 7.13696331e-02\n",
            "    0.00000000e+00 0.00000000e+00]]\n",
            "\n",
            "  [[3.96086514e-01 0.00000000e+00 0.00000000e+00 ... 5.01766801e-01\n",
            "    0.00000000e+00 4.38748181e-01]\n",
            "   [4.00723398e-01 0.00000000e+00 3.76884192e-01 ... 1.06872964e+00\n",
            "    0.00000000e+00 9.51845765e-01]\n",
            "   [3.42220008e-01 0.00000000e+00 1.38500988e+00 ... 1.04173601e+00\n",
            "    0.00000000e+00 9.06807780e-01]\n",
            "   [4.35946226e-01 0.00000000e+00 5.89700282e-01 ... 2.53115326e-01\n",
            "    0.00000000e+00 9.66090202e-01]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 6.09075725e-01]]]\n",
            "\n",
            "\n",
            " [[[0.00000000e+00 9.80807394e-02 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [1.02537923e-01 4.96120155e-01 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 1.89945078e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 1.07044756e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 1.07399285e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]]\n",
            "\n",
            "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 7.56964087e-02\n",
            "    8.06733310e-01 0.00000000e+00]\n",
            "   [5.43798387e-01 0.00000000e+00 0.00000000e+00 ... 7.04794228e-01\n",
            "    2.53478020e-01 0.00000000e+00]\n",
            "   [1.48810709e+00 0.00000000e+00 6.31276906e-01 ... 0.00000000e+00\n",
            "    0.00000000e+00 7.92786837e-01]\n",
            "   [0.00000000e+00 4.99157548e-01 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 4.82700437e-01]]\n",
            "\n",
            "  [[0.00000000e+00 2.38572970e-01 0.00000000e+00 ... 5.40127456e-01\n",
            "    0.00000000e+00 1.13017060e-01]\n",
            "   [2.17857003e-01 0.00000000e+00 3.01310956e-01 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 6.04454994e-01 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [3.27092290e-01 0.00000000e+00 0.00000000e+00 ... 3.38388830e-01\n",
            "    9.41036999e-01 0.00000000e+00]\n",
            "   [3.93630981e-01 0.00000000e+00 8.18880320e-01 ... 5.41673720e-01\n",
            "    0.00000000e+00 8.52908134e-01]]\n",
            "\n",
            "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 7.02742040e-01 0.00000000e+00 ... 0.00000000e+00\n",
            "    2.19236541e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 2.06762791e-01\n",
            "    0.00000000e+00 3.26604605e-01]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 4.86392260e-01]\n",
            "   [2.82826692e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 3.05837572e-01]]\n",
            "\n",
            "  [[3.30802292e-01 0.00000000e+00 9.77634013e-01 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 2.43486464e-03 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 1.17420163e-02 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 3.61679107e-01]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def reshaped_layer(model, x):\n",
        "    #function to get the layer wise output representation of the model for data x\n",
        "    layer_output = []\n",
        "    for i in range(3):\n",
        "        layer = model.layers[i]\n",
        "        print(layer)\n",
        "        l_op = K.function([model.layers[0].input],\n",
        "                                      [layer.output])([x])[0]\n",
        "        layer_output.append(l_op)\n",
        "    layer_output.append(K.function([model.layers[0].input],\n",
        "                                      [model.layers[4].output])([x])[0])\n",
        "    print(model.layers[4])\n",
        "    reshaped_output_layer = []\n",
        "    for output in layer_output[0:3]:\n",
        "        reshaped_output_layer.append(output.reshape(output.shape[0], output.shape[1]*output.shape[2]*output.shape[3]))\n",
        "        \n",
        "    for layer in layer_output[3:]:\n",
        "        reshaped_output_layer.append(layer)\n",
        "    \n",
        "    for layer in reshaped_output_layer:\n",
        "        assert layer.dtype == np.float32\n",
        "        #print('Normalizing the dataset')\n",
        "        layer /= np.linalg.norm(layer, axis=1).reshape(-1, 1)\n",
        "        #print('Done')        \n",
        "    return(reshaped_output_layer)\n",
        "\n",
        "reshaped_layer(model, x_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "bsYotmhJWx8O",
        "outputId": "4f0705a1-00c3-4238-e1e7-7da4ac0a94f5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<keras.layers.convolutional.Conv2D object at 0x7f9f1ec85650>\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f9f1ede7710>\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-fccfaf052353>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreshaped_output_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mreshaped_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-fccfaf052353>\u001b[0m in \u001b[0;36mreshaped_layer\u001b[0;34m(model, x)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         l_op = K.function([model.layers[0].input],\n\u001b[0;32m----> 8\u001b[0;31m                                       [layer.output])([x])[0]\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mlayer_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     layer_output.append(K.function([model.layers[0].input],\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(model_inputs)\u001b[0m\n\u001b[1;32m   4320\u001b[0m     \u001b[0mwrap_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4322\u001b[0;31m       \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4323\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mwrap_outputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4324\u001b[0m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7184\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7185\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7186\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer \"conv2d_4\" (type Conv2D).\n\nComputed output size would be negative: -1 [input_size: 1, effective_filter_size: 6, stride: 2] [Op:Conv2D]\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(28, 14, 1, 64), dtype=float32)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layerIndex, layer in enumerate(model.layers):\n",
        "    print(layerIndex)\n",
        "    func = K.function([model.get_layer(index=0).input], layer.output)\n",
        "    layerOutput = func([x_train[0]])  # input_data is a numpy array"
      ],
      "metadata": {
        "id": "pgXstGwSIp7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp = model.input                                           # input placeholder\n",
        "outputs = [layer.output for layer in model.layers]          # all layer outputs\n",
        "functor = K.function([inp, K.learning_phase()], outputs )   # evaluation function\n",
        "\n",
        "# Testing\n",
        "test = np.random.random(input_shape)[np.newaxis,...]\n",
        "layer_outs = functor([test])"
      ],
      "metadata": {
        "id": "iOK5i_uRbiTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp = model.input                                           # input placeholder\n",
        "outputs = [layer.output for layer in model.layers]          # all layer outputs\n",
        "functors = [K.function([inp], [out]) for out in outputs]    # evaluation functions\n",
        "\n",
        "# Testing\n",
        "test = np.random.random(input_shape)[np.newaxis,...]\n",
        "layer_outs = [func([test]) for func in functors]\n",
        "print(layer_outs)"
      ],
      "metadata": {
        "id": "UPOz2NgZC43B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp"
      ],
      "metadata": {
        "id": "w-ILEoh9JOjm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}